{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eac3532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_highest_frequency_word_length(string):\n",
    "    # Split the string into words\n",
    "    words = string.split()\n",
    "\n",
    "    # Count the frequency of each word\n",
    "    word_count = {}\n",
    "    for word in words:\n",
    "        if word in word_count:\n",
    "            word_count[word] += 1\n",
    "        else:\n",
    "            word_count[word] = 1\n",
    "\n",
    "    # Find the word with the highest frequency\n",
    "    max_frequency = max(word_count.values())\n",
    "\n",
    "    # Find the length of the highest-frequency word\n",
    "    highest_frequency_word_length = 0\n",
    "    for word, frequency in word_count.items():\n",
    "        if frequency == max_frequency and len(word) > highest_frequency_word_length:\n",
    "            highest_frequency_word_length = len(word)\n",
    "\n",
    "    return highest_frequency_word_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5429a299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Test cases\n",
    "string = \"The quick brown fox jumps over the lazy dog\"\n",
    "print(find_highest_frequency_word_length(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d3aa5f",
   "metadata": {},
   "source": [
    "Explanation: In this case, all words appear only once, so the highest frequency is 1. The length of the longest word is 5 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "844ac302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "string = \"apple banana apple banana apple banana\"\n",
    "print(find_highest_frequency_word_length(string)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4d452a",
   "metadata": {},
   "source": [
    "Explanation: In this case, both \"apple\" and \"banana\" appear with the same highest frequency of 3. The length of the longest word among them is 6 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d9a0e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*100)\n",
    "print(\"*\"*100)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51011efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_string(s):\n",
    "    # Create a dictionary to count the frequency of each character\n",
    "    char_count = {}\n",
    "    for char in s:\n",
    "        if char in char_count:\n",
    "            char_count[char] += 1\n",
    "        else:\n",
    "            char_count[char] = 1\n",
    "\n",
    "    # Create a dictionary to count the frequency of frequencies\n",
    "    freq_count = {}\n",
    "    for count in char_count.values():\n",
    "        if count in freq_count:\n",
    "            freq_count[count] += 1\n",
    "        else:\n",
    "            freq_count[count] = 1\n",
    "\n",
    "    # If all characters have the same frequency, it's a valid string\n",
    "    if len(freq_count) == 1:\n",
    "        return \"YES\"\n",
    "\n",
    "    # If there are exactly two different frequencies\n",
    "    if len(freq_count) == 2:\n",
    "        frequencies = list(freq_count.keys())\n",
    "        counts = list(freq_count.values())\n",
    "\n",
    "        # Check if one frequency has only one occurrence\n",
    "        if counts[0] == 1 and (frequencies[0] == 1 or abs(frequencies[0] - frequencies[1]) == 1):\n",
    "            return \"YES\"\n",
    "\n",
    "        if counts[1] == 1 and (frequencies[1] == 1 or abs(frequencies[0] - frequencies[1]) == 1):\n",
    "            return \"YES\"\n",
    "\n",
    "    # Otherwise, it's not a valid string\n",
    "    return \"NO\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48e26726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n"
     ]
    }
   ],
   "source": [
    "# Test cases\n",
    "s = \"xyxyxy\"\n",
    "print(is_valid_string(s)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd004f01",
   "metadata": {},
   "source": [
    "Explanation: In this case, all characters appear exactly twice, so the string is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a8c6ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n"
     ]
    }
   ],
   "source": [
    "s = \"aabbc\"\n",
    "print(is_valid_string(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235db7c",
   "metadata": {},
   "source": [
    "Explanation: In this case, if we remove one occurrence of 'a' or one occurrence of 'b', the remaining characters 'a', 'b', and 'c' will occur the same number of times, making the string valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e22862c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*100)\n",
    "print(\"*\"*100)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3157b562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded and converted to Excel successfully.\n",
      "Excel file: pokemon_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def download_and_convert_to_excel(url):\n",
    "    # Download the data from the provided link\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Extract the JSON data\n",
    "        data = response.json()\n",
    "\n",
    "        # Convert the JSON data to a pandas DataFrame\n",
    "        df = pd.DataFrame(data[\"pokemon\"])\n",
    "        \n",
    "\n",
    "        # Create a new Excel file and export the DataFrame\n",
    "        excel_file = \"pokemon_data.xlsx\"\n",
    "        df.to_excel(excel_file, index=False)\n",
    "\n",
    "        return excel_file\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Test the function with the provided link\n",
    "url = \"https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json\"\n",
    "excel_file = download_and_convert_to_excel(url)\n",
    "if excel_file:\n",
    "    print(\"Data downloaded and converted to Excel successfully.\")\n",
    "    print(\"Excel file:\", excel_file)\n",
    "else:\n",
    "    print(\"Failed to download data or convert it to Excel.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8557d17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*100)\n",
    "print(\"*\"*100)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "995903d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded and converted to CSV successfully.\n",
      "CSV file: nasa_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def download_and_convert_to_csv(url):\n",
    "    # Download the data from the provided link\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Extract the JSON data\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract the desired attributes from the data\n",
    "        extracted_data = []\n",
    "\n",
    "        for item in data:\n",
    "            geolocation = item.get(\"geolocation\")\n",
    "            coordinates = geolocation.get(\"coordinates\") if geolocation else []\n",
    "            extracted_item = {\n",
    "                \"Name of Earth Meteorite\": item.get(\"name\", \"\"),\n",
    "                \"ID of Earth Meteorite\": item.get(\"id\", \"\"),\n",
    "                \"Nametype\": item.get(\"nametype\", \"\"),\n",
    "                \"Meteorite Class\": item.get(\"recclass\", \"\"),\n",
    "                \"Mass of Earth Meteorite\": item.get(\"mass\", \"\"),\n",
    "                \"Year of Impact\": item.get(\"year\", \"\"),\n",
    "                \"Latitude\": float(item.get(\"reclat\", 0.0)) if item.get(\"reclat\") else 0.0,\n",
    "                \"Longitude\": float(item.get(\"reclong\", 0.0)) if item.get(\"reclong\") else 0.0,\n",
    "                \"Point Coordinates\": [int(coordinates[0]), int(coordinates[1])] if len(coordinates) == 2 else []\n",
    "            }\n",
    "            extracted_data.append(extracted_item)\n",
    "\n",
    "        # Convert the extracted data to a pandas DataFrame\n",
    "        df = pd.DataFrame(extracted_data)\n",
    "\n",
    "        # Create a new CSV file and export the DataFrame\n",
    "        csv_file = \"nasa_data.csv\"\n",
    "        df.to_csv(csv_file, index=False)\n",
    "\n",
    "        return csv_file\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Test the function with the provided link\n",
    "url = \"https://data.nasa.gov/resource/y77d-th95.json\"\n",
    "csv_file = download_and_convert_to_csv(url)\n",
    "if csv_file:\n",
    "    print(\"Data downloaded and converted to CSV successfully.\")\n",
    "    print(\"CSV file:\", csv_file)\n",
    "else:\n",
    "    print(\"Failed to download data or convert it to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc0a114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*100)\n",
    "print(\"*\"*100)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b6359d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html2text in c:\\users\\dell\\anaconda3\\lib\\site-packages (2020.1.16)\n"
     ]
    }
   ],
   "source": [
    "!pip install html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c0344cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ID\": 1371,\n",
      "    \"URL\": \"https://www.tvmaze.com/shows/1371/westworld\",\n",
      "    \"Name\": \"Westworld\",\n",
      "    \"Season\": null,\n",
      "    \"Episode Number\": null,\n",
      "    \"Type\": \"Scripted\",\n",
      "    \"Airdate\": \"\",\n",
      "    \"Airtime\": \"\",\n",
      "    \"Runtime\": 60,\n",
      "    \"Rating\": 8.2,\n",
      "    \"Summary\": \"**Westworld** is a dark odyssey about the dawn of artificial consciousness and\\nthe evolution of sin. Set at the intersection of the near future and the\\nreimagined past, it explores a world in which every human appetite, no matter\\nhow noble or depraved, can be indulged.\\n\\n\",\n",
      "    \"Medium Image Link\": \"https://static.tvmaze.com/uploads/images/medium_portrait/445/1113927.jpg\",\n",
      "    \"Original Image Link\": \"https://static.tvmaze.com/uploads/images/original_untouched/445/1113927.jpg\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import html2text\n",
    "from datetime import datetime\n",
    "\n",
    "def download_and_extract_data(url):\n",
    "    # Download the data from the API link\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Extract the JSON data\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract the desired data\n",
    "        show_id = data.get(\"id\", None)\n",
    "        show_url = data.get(\"url\", \"\")\n",
    "        show_name = data.get(\"name\", \"\")\n",
    "        season = data.get(\"season\", None)\n",
    "        episode_number = data.get(\"number\", None)\n",
    "        show_type = data.get(\"type\", \"\")\n",
    "        airdate = data.get(\"airdate\", \"\")\n",
    "        airtime = data.get(\"airtime\", \"\")\n",
    "        runtime = data.get(\"runtime\", None)\n",
    "        rating = data.get(\"rating\", {}).get(\"average\", None)\n",
    "        summary = data.get(\"summary\", \"\")\n",
    "        medium_image_link = data.get(\"image\", {}).get(\"medium\", \"\")\n",
    "        original_image_link = data.get(\"image\", {}).get(\"original\", \"\")\n",
    "\n",
    "        # Remove HTML tags from the summary\n",
    "        summary = html2text.html2text(summary)\n",
    "        \n",
    "        # Format the airdate as a date string\n",
    "        if airdate:\n",
    "            airdate = datetime.strptime(airdate, \"%Y-%m-%d\").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Format the airtime as a time string\n",
    "        if airtime:\n",
    "            airtime = datetime.strptime(airtime, \"%H:%M\").strftime(\"%I:%M %p\")\n",
    "\n",
    "\n",
    "        # Format the extracted data\n",
    "        formatted_data = {\n",
    "            \"ID\": show_id,\n",
    "            \"URL\": show_url,\n",
    "            \"Name\": show_name,\n",
    "            \"Season\": season,\n",
    "            \"Episode Number\": episode_number,\n",
    "            \"Type\": show_type,\n",
    "            \"Airdate\": airdate,\n",
    "            \"Airtime\": airtime,\n",
    "            \"Runtime\": runtime,\n",
    "            \"Rating\": rating,\n",
    "            \"Summary\": summary,\n",
    "            \"Medium Image Link\": medium_image_link,\n",
    "            \"Original Image Link\": original_image_link\n",
    "        }\n",
    "\n",
    "        return formatted_data\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Test the function with the provided API link\n",
    "url = \"http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes\"\n",
    "data = download_and_extract_data(url)\n",
    "\n",
    "if data:\n",
    "    # Print the extracted and formatted data in JSON format\n",
    "    json_data = json.dumps(data, indent=4)\n",
    "    print(json_data)\n",
    "else:\n",
    "    print(\"Failed to download data or extract the desired information.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab092443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "****************************************************************************************************\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*100)\n",
    "print(\"*\"*100)\n",
    "print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f56ec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63431184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['She is eating a delicious apple.']\n",
      "['She', 'is', 'eating', 'a', 'delicious', 'apple', '.']\n",
      "\n",
      "Counts for additional test case 1:\n",
      "{'verb': 2, 'noun': 1, 'pronoun': 1, 'adjective': 1}\n",
      "['\\nThe cat and the dog were good friends.', 'They played together in the park every day.', 'The cat was brown and fluffy,\\nwhile the dog was black and energetic.', 'They loved to chase each other and run in the grass.']\n",
      "['The', 'cat', 'and', 'the', 'dog', 'were', 'good', 'friends', '.', 'They', 'played', 'together', 'in', 'the', 'park', 'every', 'day', '.', 'The', 'cat', 'was', 'brown', 'and', 'fluffy', ',', 'while', 'the', 'dog', 'was', 'black', 'and', 'energetic', '.', 'They', 'loved', 'to', 'chase', 'each', 'other', 'and', 'run', 'in', 'the', 'grass', '.']\n",
      "\n",
      "Counts for additional test case 2:\n",
      "{'verb': 9, 'noun': 8, 'pronoun': 2, 'adjective': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def count_pos(text):\n",
    "    \n",
    "    # Tokenize the text into sentences and then words\n",
    "    sentences = sent_tokenize(text)\n",
    "    print(sentences)\n",
    "    words = word_tokenize(text)\n",
    "    print(words)\n",
    "    \n",
    "    # Perform part-of-speech tagging\n",
    "    tagged_words = pos_tag(words)\n",
    "\n",
    "    # Initialize counts\n",
    "    counts = {\n",
    "        'verb': 0,\n",
    "        'noun': 0,\n",
    "        'pronoun': 0,\n",
    "        'adjective': 0\n",
    "    }\n",
    "\n",
    "    # Count the occurrences of each part of speech\n",
    "    for word, tag in tagged_words:\n",
    "        if tag.startswith('VB'):  # Verbs\n",
    "            counts['verb'] += 1\n",
    "        elif tag.startswith('NN'):  # Nouns\n",
    "            counts['noun'] += 1\n",
    "        elif tag.startswith('PR'):  # Pronouns\n",
    "            counts['pronoun'] += 1\n",
    "        elif tag.startswith('JJ'):  # Adjectives\n",
    "            counts['adjective'] += 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "# test case 1: Count parts of speech in a complex sentence\n",
    "sentence = \"She is eating a delicious apple.\"\n",
    "counts = count_pos(sentence)\n",
    "print(\"\\nCounts for additional test case 1:\")\n",
    "print(counts)\n",
    "\n",
    "# test case 2: Count parts of speech in a longer paragraph\n",
    "long_paragraph = \"\"\"\n",
    "The cat and the dog were good friends. They played together in the park every day. The cat was brown and fluffy,\n",
    "while the dog was black and energetic. They loved to chase each other and run in the grass.\n",
    "\"\"\"\n",
    "counts = count_pos(long_paragraph)\n",
    "print(\"\\nCounts for additional test case 2:\")\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b61b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2076abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
